{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1430623,"sourceType":"datasetVersion","datasetId":609422},{"sourceId":3144322,"sourceType":"datasetVersion","datasetId":1887646},{"sourceId":3799317,"sourceType":"datasetVersion","datasetId":2265176},{"sourceId":7510067,"sourceType":"datasetVersion","datasetId":767979}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import OneCycleLR\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom transformers import AutoConfig, CvtForImageClassification\nimport numpy as np\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom PIL import Image, UnidentifiedImageError\nimport os\nfrom sklearn.metrics import confusion_matrix, f1_score, classification_report\nimport matplotlib.pyplot as plt\nfrom torch.utils.tensorboard import SummaryWriter\nimport seaborn as sns\nimport random\nfrom collections import Counter\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# Pastikan Anda telah menginstal albumentations:\n# !pip install albumentations\n# !pip install albumentations[pytorch]\n\n# Set seed for reproducibility\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nBATCH_SIZE = 16\nNUM_CLASSES = 20\nEPOCHS = 100\nLEARNING_RATE = 0.00015836211715780283  # Learning rate yang lebih tinggi\nWEIGHT_DECAY = 0.00002683\nIMAGE_SIZE = 224\nDATASET_PATH = '/kaggle/input/d/phiard/aksara-jawa/v3/v3'  # Pastikan path ini benar\n\n# Konfigurasi model\nconfig = AutoConfig.from_pretrained(\"microsoft/cvt-13\")\nconfig.num_labels = NUM_CLASSES\nconfig.hidden_dropout_prob = 0.1  # Mengurangi dropout\n\nmodel = CvtForImageClassification.from_pretrained(\n    \"microsoft/cvt-13\", config=config, ignore_mismatched_sizes=True\n).to(device)\n\n# Pastikan semua parameter dioptimalkan\nfor param in model.parameters():\n    param.requires_grad = True\n\n# Definisikan Augmentasi Data dengan Albumentations untuk Pelatihan\ntrain_transform = A.Compose([\n    A.RandomResizedCrop(height=IMAGE_SIZE, width=IMAGE_SIZE, scale=(0.8, 1.0)),\n    A.HorizontalFlip(p=0.5),\n    A.Rotate(limit=15, p=0.5),\n    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n    A.HueSaturationValue(p=0.5),\n    A.Normalize(mean=(0.485, 0.456, 0.406), \n                std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])\n\n# Transformasi untuk data validasi tanpa augmentasi\nval_transform = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),\n    transforms.CenterCrop(IMAGE_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                         std=[0.229, 0.224, 0.225]),\n])\n\nclass CustomImageFolderAlbumentations(Dataset):\n    def __init__(self, root, transform=None):\n        self.samples = []\n        self.targets = []\n        self.transform = transform\n        self.classes, self.class_to_idx = self._find_classes(root)\n        self.num_classes = len(self.classes)\n\n        for target_class in sorted(self.class_to_idx.keys()):\n            class_index = self.class_to_idx[target_class]\n            target_dir = os.path.join(root, target_class)\n            if not os.path.isdir(target_dir):\n                continue\n            for root_, _, fnames in sorted(os.walk(target_dir, followlinks=True)):\n                for fname in sorted(fnames):\n                    path = os.path.join(root_, fname)\n                    try:\n                        with Image.open(path) as img:\n                            img.verify()  # Verifikasi integritas gambar\n                        self.samples.append((path, class_index))\n                        self.targets.append(class_index)\n                    except (UnidentifiedImageError, OSError):\n                        print(f\"Gambar korup dilewati: {path}\")\n                        continue\n\n    def __getitem__(self, index):\n        path, target = self.samples[index]\n        with Image.open(path) as sample:\n            sample = sample.convert('RGB')\n\n        if self.transform:\n            if isinstance(self.transform, A.core.composition.Compose):\n                # Jika menggunakan Albumentations\n                sample = np.array(sample)\n                sample = self.transform(image=sample)['image']\n            else:\n                # Jika menggunakan torchvision.transforms\n                sample = self.transform(sample)\n\n        return sample, target\n\n    def __len__(self):\n        return len(self.samples)\n\n    def _find_classes(self, dir):\n        classes = [d.name for d in os.scandir(dir) if d.is_dir()]\n        classes.sort()\n        class_to_idx = {classes[i]: i for i in range(len(classes))}\n        return classes, class_to_idx\n\ntrain_dir = os.path.join(DATASET_PATH, 'train')\nval_dir = os.path.join(DATASET_PATH, 'val')\n\n# Membuat dataset dengan transformasi yang sesuai\ntrain_dataset = CustomImageFolderAlbumentations(train_dir, transform=train_transform)\nval_dataset = CustomImageFolderAlbumentations(val_dir, transform=val_transform)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n\n# Verifikasi distribusi kelas\ncounter = Counter(train_dataset.targets)\nprint(\"Distribusi Kelas dalam Training Set:\")\nfor cls, count in counter.items():\n    print(f\"Kelas {cls}: {count} sampel\")\n\n# Menghitung class weights\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(train_dataset.targets),\n    y=train_dataset.targets\n)\nclass_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\nprint(f\"Class Weights: {class_weights}\")\n\n# Definisikan loss function tanpa label smoothing\ncriterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.0)\n\n# Definisikan optimizer dengan AdamW\noptimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n\n# Menggunakan scheduler OneCycleLR\nscheduler = OneCycleLR(optimizer, max_lr=LEARNING_RATE, steps_per_epoch=len(train_loader), epochs=EPOCHS)\n\n# Implementasi MixUp\ndef mixup_data(x, y, alpha=0.2):\n    '''Returns mixed inputs, pairs of targets, and lambda'''\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n    batch_size = x.size()[0]\n    if torch.cuda.is_available():\n        index = torch.randperm(batch_size).cuda()\n    else:\n        index = torch.randperm(batch_size)\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n\n# Implementasi CutMix (Opsional)\ndef cutmix_data(x, y, alpha=1.0):\n    '''Returns cutmixed inputs, pairs of targets, and lambda'''\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n    batch_size, C, H, W = x.size()\n    if torch.cuda.is_available():\n        index = torch.randperm(batch_size).cuda()\n    else:\n        index = torch.randperm(batch_size)\n    y_a, y_b = y, y[index]\n    \n    # Generate a random rectangle\n    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n    x[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]\n    # Adjust lambda to exactly match pixel ratio\n    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size(-1) * x.size(-2)))\n    return x, y_a, y_b, lam\n\ndef rand_bbox(size, lam):\n    W = size[3]\n    H = size[2]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = int(W * cut_rat)\n    cut_h = int(H * cut_rat)\n\n    # uniform\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n\n    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n    bby1 = np.clip(cy - cut_h // 2, 0, H)\n    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n    bby2 = np.clip(cy + cut_h // 2, 0, H)\n\n    return bbx1, bby1, bbx2, bby2\n\ndef train_epoch(model, loader, optimizer, criterion, scheduler, use_mixup=True, use_cutmix=False, alpha=0.2, clip_grad=True, max_norm=1.0):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n    for data, target in loader:\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        \n        if use_mixup:\n            data, targets_a, targets_b, lam = mixup_data(data, target, alpha=alpha)\n            outputs = model(data).logits\n            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n        elif use_cutmix:\n            data, targets_a, targets_b, lam = cutmix_data(data, target, alpha=alpha)\n            outputs = model(data).logits\n            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n        else:\n            outputs = model(data).logits\n            loss = criterion(outputs, target)\n        \n        loss.backward()\n        \n        if clip_grad:\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n        \n        optimizer.step()\n        scheduler.step()\n        \n        total_loss += loss.item()\n        \n        if use_mixup or use_cutmix:\n            _, predicted = torch.max(outputs, 1)\n            # Akurasi dihitung berdasarkan kombinasi prediksi terhadap kedua label dengan proporsi lam dan (1 - lam)\n            correct += (lam * predicted.eq(targets_a).sum().item() + (1 - lam) * predicted.eq(targets_b).sum().item())\n        else:\n            _, predicted = outputs.max(1)\n            correct += predicted.eq(target).sum().item()\n        total += target.size(0)\n    return total_loss / len(loader), 100. * correct / total\n\ndef validate(model, loader, criterion, use_mixup=False):\n    model.eval()\n    total_loss = 0\n    correct = 0\n    total = 0\n    all_targets = []\n    all_predictions = []\n    with torch.no_grad():\n        for data, target in loader:\n            data, target = data.to(device), target.to(device)\n            if use_mixup:\n                data, targets_a, targets_b, lam = mixup_data(data, target, alpha=0.2)\n                outputs = model(data).logits\n                loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n            else:\n                outputs = model(data).logits\n                loss = criterion(outputs, target)\n            total_loss += loss.item()\n            _, predicted = outputs.max(1)\n            correct += predicted.eq(target).sum().item()\n            total += target.size(0)\n            all_targets.extend(target.cpu().numpy())\n            all_predictions.extend(predicted.cpu().numpy())\n    f1 = f1_score(all_targets, all_predictions, average='weighted')\n    return total_loss / len(loader), 100. * correct / total, f1, all_targets, all_predictions\n\n# Setup TensorBoard writer\nwriter = SummaryWriter()\n\n# Initialize metrics lists\ntrain_losses = []\ntrain_accs = []\nval_losses = []\nval_accs = []\nval_f1_scores = []\n\n# Early stopping parameters\npatience = 20  # Meningkatkan patience untuk early stopping\ncounter = 0\nbest_val_acc = 0\n\n# Training Loop\nfor epoch in range(EPOCHS):\n    train_loss, train_acc = train_epoch(\n        model, \n        train_loader, \n        optimizer, \n        criterion, \n        scheduler, \n        use_mixup=True, \n        use_cutmix=False,  # Atur ke True jika ingin menggunakan CutMix\n        alpha=0.2, \n        clip_grad=True, \n        max_norm=1.0\n    )\n    val_loss, val_acc, val_f1, all_targets, all_predictions = validate(model, val_loader, criterion, use_mixup=False)\n    \n    # Menyimpan metrik\n    train_losses.append(train_loss)\n    train_accs.append(train_acc)\n    val_losses.append(val_loss)\n    val_accs.append(val_acc)\n    val_f1_scores.append(val_f1)\n\n    # Logging ke TensorBoard\n    writer.add_scalars('Loss', {'Train': train_loss, 'Val': val_loss}, epoch)\n    writer.add_scalars('Accuracy', {'Train': train_acc, 'Val': val_acc}, epoch)\n    writer.add_scalar('F1_Score/Val', val_f1, epoch)\n\n    # Menyimpan model terbaik\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), \"best_cvt_model.pth\")\n        counter = 0  # Reset counter jika ada peningkatan\n    else:\n        counter += 1\n\n    # Early stopping\n    if counter >= patience:\n        print(f\"Early stopping setelah epoch {epoch+1} karena tidak ada peningkatan akurasi validasi.\")\n        break\n\n    # Menampilkan progres\n    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, Val F1 Score: {val_f1:.4f}\")\n\nwriter.close()\n\n# Plot Confusion Matrix untuk Validasi\ndef plot_confusion_matrix(targets, predictions, class_names):\n    cm = confusion_matrix(targets, predictions)\n    plt.figure(figsize=(12, 10))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel(\"Prediksi\")\n    plt.ylabel(\"Sebenarnya\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n\nplot_confusion_matrix(all_targets, all_predictions, train_dataset.classes)\n\n# Tampilkan prediksi per kelas\ndef show_predictions_per_class(model, dataset, num_classes=20, cols=5):\n    model.eval()\n    rows = (num_classes + cols - 1) // cols\n    fig, axs = plt.subplots(rows, cols, figsize=(15, 3 * rows))\n    axs = axs.flatten()\n\n    class_images = {i: None for i in range(num_classes)}\n\n    for i in range(len(dataset)):\n        image, label = dataset[i]\n        image = image.unsqueeze(0).to(device)\n        with torch.no_grad():\n            output = model(image).logits\n            _, predicted = output.max(1)\n            if class_images[label] is None and predicted.item() == label:\n                class_images[label] = (image.squeeze().cpu(), label, predicted.item())\n                if all(value is not None for value in class_images.values()):\n                    break\n\n    for i in range(num_classes):\n        ax = axs[i]\n        if class_images[i] is not None:\n            img, true_label, pred_label = class_images[i]\n            # Denormalisasi gambar\n            img = img * torch.tensor([0.229, 0.224, 0.225]).view(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n            img = img.permute(1, 2, 0).numpy()\n            img = np.clip(img, 0, 1)\n            ax.imshow(img)\n            ax.set_title(f\"True: {train_dataset.classes[true_label]}\\nPred: {train_dataset.classes[pred_label]}\")\n            ax.axis('off')\n        else:\n            ax.text(0.5, 0.5, 'No Prediction', ha='center', va='center')\n            ax.axis('off')\n\n    for j in range(num_classes, len(axs)):\n        axs[j].axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\nshow_predictions_per_class(model, val_dataset)\n\n# Plot Loss dan Akurasi\nplt.figure(figsize=(12, 5))\n\n# Plot Loss\nplt.subplot(1, 2, 1)\nplt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\nplt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\n# Plot Akurasi\nplt.subplot(1, 2, 2)\nplt.plot(range(1, len(train_accs) + 1), train_accs, label='Train Accuracy')\nplt.plot(range(1, len(val_accs) + 1), val_accs, label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# Evaluasi Tambahan: Classification Report\ndef classification_metrics(loader):\n    model.eval()\n    all_targets = []\n    all_predictions = []\n    with torch.no_grad():\n        for data, target in loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data).logits\n            _, predicted = torch.max(output, 1)\n            all_targets.extend(target.cpu().numpy())\n            all_predictions.extend(predicted.cpu().numpy())\n    print(classification_report(all_targets, all_predictions, target_names=train_dataset.classes))\n\nprint(\"Classification Report untuk Training Set:\")\nclassification_metrics(train_loader)\n\nprint(\"Classification Report untuk Validation Set:\")\nclassification_metrics(val_loader)\n","metadata":{"id":"iC1-ZNmCw15s","execution":{"iopub.status.busy":"2024-12-17T10:29:28.880495Z","iopub.execute_input":"2024-12-17T10:29:28.880907Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Some weights of CvtForImageClassification were not initialized from the model checkpoint at microsoft/cvt-13 and are newly initialized because the shapes did not match:\n- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([20]) in the model instantiated\n- classifier.weight: found shape torch.Size([1000, 384]) in the checkpoint and torch.Size([20, 384]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Distribusi Kelas dalam Training Set:\nKelas 0: 114 sampel\nKelas 1: 108 sampel\nKelas 2: 108 sampel\nKelas 3: 108 sampel\nKelas 4: 108 sampel\nKelas 5: 102 sampel\nKelas 6: 108 sampel\nKelas 7: 108 sampel\nKelas 8: 108 sampel\nKelas 9: 108 sampel\nKelas 10: 108 sampel\nKelas 11: 102 sampel\nKelas 12: 108 sampel\nKelas 13: 108 sampel\nKelas 14: 108 sampel\nKelas 15: 108 sampel\nKelas 16: 108 sampel\nKelas 17: 108 sampel\nKelas 18: 108 sampel\nKelas 19: 108 sampel\nClass Weights: tensor([0.9447, 0.9972, 0.9972, 0.9972, 0.9972, 1.0559, 0.9972, 0.9972, 0.9972,\n        0.9972, 0.9972, 1.0559, 0.9972, 0.9972, 0.9972, 0.9972, 0.9972, 0.9972,\n        0.9972, 0.9972], device='cuda:0')\nEpoch 1/100\nTrain Loss: 2.9955, Train Acc: 6.38%\nVal Loss: 2.9410, Val Acc: 13.54%, Val F1 Score: 0.0937\nEpoch 2/100\nTrain Loss: 2.9438, Train Acc: 10.88%\nVal Loss: 2.8638, Val Acc: 19.79%, Val F1 Score: 0.1600\nEpoch 3/100\nTrain Loss: 2.8650, Train Acc: 16.80%\nVal Loss: 2.6901, Val Acc: 29.17%, Val F1 Score: 0.2562\nEpoch 4/100\nTrain Loss: 2.6936, Train Acc: 26.26%\nVal Loss: 2.3985, Val Acc: 42.71%, Val F1 Score: 0.3893\nEpoch 5/100\nTrain Loss: 2.3836, Train Acc: 40.20%\nVal Loss: 1.8310, Val Acc: 54.38%, Val F1 Score: 0.4869\nEpoch 6/100\nTrain Loss: 2.0180, Train Acc: 49.83%\nVal Loss: 1.5250, Val Acc: 56.88%, Val F1 Score: 0.5389\nEpoch 7/100\nTrain Loss: 1.6900, Train Acc: 59.15%\nVal Loss: 1.3600, Val Acc: 57.50%, Val F1 Score: 0.5530\nEpoch 8/100\nTrain Loss: 1.4574, Train Acc: 63.55%\nVal Loss: 0.6143, Val Acc: 88.75%, Val F1 Score: 0.8874\nEpoch 9/100\nTrain Loss: 1.2785, Train Acc: 66.39%\nVal Loss: 0.4775, Val Acc: 87.08%, Val F1 Score: 0.8664\nEpoch 10/100\nTrain Loss: 1.1318, Train Acc: 69.92%\nVal Loss: 0.5601, Val Acc: 87.71%, Val F1 Score: 0.8755\nEpoch 11/100\nTrain Loss: 1.1604, Train Acc: 67.47%\nVal Loss: 0.4253, Val Acc: 87.71%, Val F1 Score: 0.8784\nEpoch 12/100\nTrain Loss: 1.1753, Train Acc: 67.15%\nVal Loss: 0.5291, Val Acc: 88.75%, Val F1 Score: 0.8759\nEpoch 13/100\nTrain Loss: 1.0502, Train Acc: 71.09%\nVal Loss: 0.3298, Val Acc: 90.83%, Val F1 Score: 0.9069\nEpoch 14/100\nTrain Loss: 1.0544, Train Acc: 70.71%\nVal Loss: 0.4489, Val Acc: 88.12%, Val F1 Score: 0.8809\nEpoch 15/100\nTrain Loss: 1.0868, Train Acc: 69.65%\nVal Loss: 0.3570, Val Acc: 90.21%, Val F1 Score: 0.9017\nEpoch 16/100\nTrain Loss: 1.1577, Train Acc: 66.57%\nVal Loss: 0.4122, Val Acc: 90.00%, Val F1 Score: 0.8984\nEpoch 17/100\nTrain Loss: 1.0859, Train Acc: 68.04%\nVal Loss: 0.5051, Val Acc: 87.92%, Val F1 Score: 0.8769\nEpoch 18/100\nTrain Loss: 1.0408, Train Acc: 69.55%\nVal Loss: 0.4730, Val Acc: 87.92%, Val F1 Score: 0.8752\nEpoch 19/100\nTrain Loss: 0.9726, Train Acc: 72.52%\nVal Loss: 0.3729, Val Acc: 90.21%, Val F1 Score: 0.9015\nEpoch 20/100\nTrain Loss: 1.0253, Train Acc: 69.68%\nVal Loss: 0.4874, Val Acc: 90.00%, Val F1 Score: 0.8921\nEpoch 21/100\nTrain Loss: 0.9672, Train Acc: 71.63%\nVal Loss: 0.4609, Val Acc: 89.17%, Val F1 Score: 0.8900\nEpoch 22/100\nTrain Loss: 0.9844, Train Acc: 70.51%\nVal Loss: 0.3997, Val Acc: 91.46%, Val F1 Score: 0.9151\nEpoch 23/100\nTrain Loss: 0.9646, Train Acc: 72.01%\nVal Loss: 0.6040, Val Acc: 87.08%, Val F1 Score: 0.8625\nEpoch 24/100\nTrain Loss: 0.9476, Train Acc: 71.37%\nVal Loss: 0.3985, Val Acc: 92.29%, Val F1 Score: 0.9205\nEpoch 25/100\nTrain Loss: 0.9511, Train Acc: 71.75%\nVal Loss: 0.4932, Val Acc: 90.62%, Val F1 Score: 0.9060\nEpoch 26/100\nTrain Loss: 0.9369, Train Acc: 72.39%\nVal Loss: 0.5903, Val Acc: 87.50%, Val F1 Score: 0.8717\nEpoch 27/100\nTrain Loss: 0.9791, Train Acc: 70.31%\nVal Loss: 0.4503, Val Acc: 90.42%, Val F1 Score: 0.9029\nEpoch 28/100\nTrain Loss: 0.9020, Train Acc: 72.68%\nVal Loss: 0.5090, Val Acc: 89.79%, Val F1 Score: 0.8953\nEpoch 29/100\nTrain Loss: 0.9736, Train Acc: 69.90%\nVal Loss: 0.2991, Val Acc: 92.92%, Val F1 Score: 0.9282\nEpoch 30/100\nTrain Loss: 0.9050, Train Acc: 72.61%\nVal Loss: 0.3298, Val Acc: 92.71%, Val F1 Score: 0.9268\nEpoch 31/100\nTrain Loss: 0.9741, Train Acc: 69.55%\nVal Loss: 0.7187, Val Acc: 85.21%, Val F1 Score: 0.8517\nEpoch 32/100\nTrain Loss: 0.9316, Train Acc: 71.24%\nVal Loss: 0.4167, Val Acc: 92.92%, Val F1 Score: 0.9286\nEpoch 33/100\nTrain Loss: 0.8778, Train Acc: 72.86%\nVal Loss: 0.4991, Val Acc: 91.25%, Val F1 Score: 0.9111\nEpoch 34/100\nTrain Loss: 0.9103, Train Acc: 71.56%\nVal Loss: 0.4914, Val Acc: 91.88%, Val F1 Score: 0.9175\n","output_type":"stream"}],"execution_count":null}]}