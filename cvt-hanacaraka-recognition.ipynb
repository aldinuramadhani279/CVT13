{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1430623,"sourceType":"datasetVersion","datasetId":609422},{"sourceId":3144322,"sourceType":"datasetVersion","datasetId":1887646},{"sourceId":3952946,"sourceType":"datasetVersion","datasetId":1554380},{"sourceId":7510067,"sourceType":"datasetVersion","datasetId":767979}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom transformers import AutoImageProcessor, CvtForImageClassification, AutoConfig\nimport numpy as np\nimport optuna\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom PIL import Image, UnidentifiedImageError\nimport os\nfrom sklearn.metrics import f1_score\nfrom torch.utils.tensorboard import SummaryWriter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Tentukan device untuk training (GPU jika tersedia)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Hyperparameters dan paths\nBATCH_SIZE = 32\nNUM_CLASSES = 20\nIMAGE_SIZE = 224\nDATASET_PATH = '/kaggle/input/d/phiard/aksara-jawa/v3/v3'\n\n# Load dan konfigurasi model CvT-13\nconfig = AutoConfig.from_pretrained(\"microsoft/cvt-13\")\nconfig.num_labels = NUM_CLASSES\nimage_processor = AutoImageProcessor.from_pretrained(\"microsoft/cvt-13\")\n\n# Custom dataset untuk memuat dataset dengan struktur folder baru\nclass CustomImageFolder(Dataset):\n    def __init__(self, root, transform=None):\n        self.samples = []\n        self.targets = []\n        self.transform = transform\n        classes, class_to_idx = self._find_classes(root)\n        self.class_to_idx = class_to_idx\n        self.classes = classes\n        for target_class in sorted(class_to_idx.keys()):\n            class_index = class_to_idx[target_class]\n            target_dir = os.path.join(root, target_class)\n            if not os.path.isdir(target_dir):\n                continue\n            for root_, _, fnames in sorted(os.walk(target_dir, followlinks=True)):\n                for fname in sorted(fnames):\n                    path = os.path.join(root_, fname)\n                    try:\n                        with Image.open(path) as img:\n                            img.verify()\n                        self.samples.append((path, class_index))\n                        self.targets.append(class_index)\n                    except (UnidentifiedImageError, OSError):\n                        print(f\"Gambar korup dilewati: {path}\")\n                        continue\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, index):\n        path, target = self.samples[index]\n        with Image.open(path) as sample:\n            sample = sample.convert('RGB')\n        inputs = image_processor(images=sample, return_tensors=\"pt\")\n        return inputs[\"pixel_values\"].squeeze(0), target\n\n    def _find_classes(self, dir):\n        classes = [d.name for d in os.scandir(dir) if d.is_dir()]\n        classes.sort()\n        class_to_idx = {classes[i]: i for i in range(len(classes))}\n        return classes, class_to_idx\n\n\n# Fungsi untuk melatih model\ndef train_model(model, train_loader, val_loader, optimizer, criterion, scheduler, epochs=10):\n    best_val_acc = 0\n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0\n        train_correct = 0\n        train_total = 0\n        for data, target in train_loader:\n            data, target = data.to(device), target.to(device)\n            optimizer.zero_grad()\n            output = model(data).logits\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            _, predicted = output.max(1)\n            train_correct += predicted.eq(target).sum().item()\n            train_total += target.size(0)\n\n        train_acc = 100. * train_correct / train_total\n\n        # Validation\n        model.eval()\n        val_loss = 0\n        val_correct = 0\n        val_total = 0\n        with torch.no_grad():\n            for data, target in val_loader:\n                data, target = data.to(device), target.to(device)\n                output = model(data).logits\n                loss = criterion(output, target)\n                val_loss += loss.item()\n                _, predicted = output.max(1)\n                val_correct += predicted.eq(target).sum().item()\n                val_total += target.size(0)\n\n        val_acc = 100. * val_correct / val_total\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n\n        scheduler.step()\n\n    return best_val_acc\n\n# Fungsi objektif untuk Optuna\ndef objective(trial):\n    # Tentukan hyperparameter yang dicari\n    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n    weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-3)\n    hidden_dropout_prob = trial.suggest_uniform('hidden_dropout_prob', 0.1, 0.5)\n\n    # Buat model dengan hyperparameter yang dicoba\n    model = CvtForImageClassification.from_pretrained(\"microsoft/cvt-13\", config=config, ignore_mismatched_sizes=True).to(device)\n    model.config.hidden_dropout_prob = hidden_dropout_prob\n\n    # Tentukan optimizers dan scheduler\n    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    scheduler = CosineAnnealingLR(optimizer, T_max=10)\n\n    # Tentukan loss function\n    train_dataset = CustomImageFolder(os.path.join(DATASET_PATH, 'train'))\n    val_dataset = CustomImageFolder(os.path.join(DATASET_PATH, 'val'))\n    class_weights = compute_class_weight('balanced', classes=np.unique(train_dataset.targets), y=train_dataset.targets)\n    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n\n    # DataLoader\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n    # Latih model\n    best_val_acc = train_model(model, train_loader, val_loader, optimizer, criterion, scheduler)\n\n    # Kembalikan hasil evaluasi (kita menggunakan akurasi validasi)\n    return best_val_acc\n\n# Set up Optuna study\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=50)  # Uji 50 kombinasi\n\n# Hasil optimasi\nprint(f'Best trial: {study.best_trial.number}')\nprint(f'  Best learning rate: {study.best_trial.params[\"learning_rate\"]}')\nprint(f'  Best weight decay: {study.best_trial.params[\"weight_decay\"]}')\nprint(f'  Best dropout probability: {study.best_trial.params[\"hidden_dropout_prob\"]}')\n","metadata":{"id":"iC1-ZNmCw15s","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tentukan device untuk training (GPU jika tersedia)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:15:14.055333Z","iopub.status.idle":"2024-12-16T16:15:14.055607Z","shell.execute_reply.started":"2024-12-16T16:15:14.055471Z","shell.execute_reply":"2024-12-16T16:15:14.055485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hyperparameters dan paths\nBATCH_SIZE = 32\nNUM_CLASSES = 20\nEPOCHS = 50\nLEARNING_RATE = 0.0005\nWEIGHT_DECAY = 0.00001\nIMAGE_SIZE = 224\nDATASET_PATH = '/kaggle/input/d/phiard/aksara-jawa/v3/v3'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:15:14.056829Z","iopub.status.idle":"2024-12-16T16:15:14.057168Z","shell.execute_reply.started":"2024-12-16T16:15:14.056991Z","shell.execute_reply":"2024-12-16T16:15:14.057006Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load dan konfigurasi model CvT-13\nconfig = AutoConfig.from_pretrained(\"microsoft/cvt-13\")\nconfig.num_labels = NUM_CLASSES\nconfig.hidden_dropout_prob = 0.01\nimage_processor = AutoImageProcessor.from_pretrained(\"microsoft/cvt-13\")\nmodel = CvtForImageClassification.from_pretrained(\n    \"microsoft/cvt-13\", config=config, ignore_mismatched_sizes=True\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:15:14.058695Z","iopub.status.idle":"2024-12-16T16:15:14.059145Z","shell.execute_reply.started":"2024-12-16T16:15:14.058903Z","shell.execute_reply":"2024-12-16T16:15:14.058925Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import transforms\n\n# Transformasi untuk data training\ntrain_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),            # Flipping horizontal acak\n    transforms.RandomRotation(20),                # Rotasi acak antara -20 hingga 20 derajat\n    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.8, 1.0)),  # Crop acak dengan ukuran tertentu\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Variasi warna\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalisasi\n])\n\n# Transformasi untuk data validasi (tanpa augmentasi)\nval_transform = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),               # Resize gambar untuk validasi\n    transforms.CenterCrop(IMAGE_SIZE),           # Crop di tengah\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalisasi\n])\n\n# CustomImageFolder dengan transformasi yang telah diubah\nclass CustomImageFolder(Dataset):\n    def __init__(self, root, transform=None):\n        self.samples = []\n        self.targets = []\n        self.transform = transform\n        classes, class_to_idx = self._find_classes(root)\n        self.class_to_idx = class_to_idx\n        self.classes = classes\n\n        for target_class in sorted(class_to_idx.keys()):\n            class_index = class_to_idx[target_class]\n            target_dir = os.path.join(root, target_class)\n            if not os.path.isdir(target_dir):\n                continue\n            for root_, _, fnames in sorted(os.walk(target_dir, followlinks=True)):\n                for fname in sorted(fnames):\n                    path = os.path.join(root_, fname)\n                    try:\n                        with Image.open(path) as img:\n                            img.verify()\n                        self.samples.append((path, class_index))\n                        self.targets.append(class_index)\n                    except (UnidentifiedImageError, OSError):\n                        print(f\"Gambar korup dilewati: {path}\")\n                        continue\n\n    def __getitem__(self, index):\n        path, target = self.samples[index]\n        with Image.open(path) as sample:\n            sample = sample.convert('RGB')\n        \n        # Apply transformation\n        if self.transform:\n            sample = self.transform(sample)\n        \n        return sample, target\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, index):\n        path, target = self.samples[index]\n        with Image.open(path) as sample:\n            sample = sample.convert('RGB')\n        inputs = image_processor(images=sample, return_tensors=\"pt\")\n        return inputs[\"pixel_values\"].squeeze(0), target\n\n    def _find_classes(self, dir):\n        classes = [d.name for d in os.scandir(dir) if d.is_dir()]\n        classes.sort()\n        class_to_idx = {classes[i]: i for i in range(len(classes))}\n        return classes, class_to_idx\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:15:14.060557Z","iopub.status.idle":"2024-12-16T16:15:14.060831Z","shell.execute_reply.started":"2024-12-16T16:15:14.060700Z","shell.execute_reply":"2024-12-16T16:15:14.060714Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load dataset dan lakukan pembagian 80/20\ntrain_dataset = CustomImageFolder(os.path.join(DATASET_PATH, 'train'))\nval_dataset = CustomImageFolder(os.path.join(DATASET_PATH, 'val'))\n\n# Pembagian test dataset ke training dan validation 80/20\ntrain_size = int(0.8 * len(train_dataset))\ntest_size = len(train_dataset) - train_size\ntrain_dataset, test_dataset = random_split(train_dataset, [train_size, test_size])\n\n# Membuat DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:15:14.062170Z","iopub.status.idle":"2024-12-16T16:15:14.062463Z","shell.execute_reply.started":"2024-12-16T16:15:14.062325Z","shell.execute_reply":"2024-12-16T16:15:14.062340Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hitung class weights untuk ketidakseimbangan kelas\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(train_dataset.dataset.targets),\n    y=train_dataset.dataset.targets\n)\nclass_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:15:14.063304Z","iopub.status.idle":"2024-12-16T16:15:14.063594Z","shell.execute_reply.started":"2024-12-16T16:15:14.063450Z","shell.execute_reply":"2024-12-16T16:15:14.063465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loss function\ncriterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)\n\n# Optimizer\noptimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n\n# Scheduler\nscheduler = CosineAnnealingLR(optimizer, T_max=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:15:14.064573Z","iopub.status.idle":"2024-12-16T16:15:14.064834Z","shell.execute_reply.started":"2024-12-16T16:15:14.064706Z","shell.execute_reply":"2024-12-16T16:15:14.064719Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fungsi train\ndef train(model, loader, optimizer, criterion):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n    for data, target in loader:\n        data, target = data.to(device), target.to(device)\n        output = model(data).logits\n        loss = criterion(output, target)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        _, predicted = output.max(1)\n        correct += predicted.eq(target).sum().item()\n        total += target.size(0)\n    return total_loss / len(loader), 100. * correct / total\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:15:14.065640Z","iopub.status.idle":"2024-12-16T16:15:14.065906Z","shell.execute_reply.started":"2024-12-16T16:15:14.065769Z","shell.execute_reply":"2024-12-16T16:15:14.065783Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fungsi validasi\ndef validate(model, loader, criterion):\n    model.eval()\n    total_loss = 0\n    correct = 0\n    total = 0\n    all_targets = []\n    all_predictions = []\n    with torch.no_grad():\n        for data, target in loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data).logits\n            loss = criterion(output, target)\n            total_loss += loss.item()\n            _, predicted = output.max(1)\n            correct += predicted.eq(target).sum().item()\n            total += target.size(0)\n            all_targets.extend(target.cpu().numpy())\n            all_predictions.extend(predicted.cpu().numpy())\n    f1 = f1_score(all_targets, all_predictions, average='weighted')\n    return total_loss / len(loader), 100. * correct / total, f1, all_targets, all_predictions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:15:14.067200Z","iopub.status.idle":"2024-12-16T16:15:14.067519Z","shell.execute_reply.started":"2024-12-16T16:15:14.067368Z","shell.execute_reply":"2024-12-16T16:15:14.067382Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training loop\nwriter = SummaryWriter()\nbest_val_acc = 0\ntrain_losses, train_accs, val_losses, val_accs, val_f1_scores = [], [], [], [], []\n\nfor epoch in range(EPOCHS):\n    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n    val_loss, val_acc, val_f1, all_targets, all_predictions = validate(model, val_loader, criterion)\n\n    train_losses.append(train_loss)\n    train_accs.append(train_acc)\n    val_losses.append(val_loss)\n    val_accs.append(val_acc)\n    val_f1_scores.append(val_f1)\n\n    writer.add_scalars('Loss', {'Train': train_loss, 'Val': val_loss}, epoch)\n    writer.add_scalars('Accuracy', {'Train': train_acc, 'Val': val_acc}, epoch)\n    writer.add_scalar('F1_Score/Val', val_f1, epoch)\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), \"best_cvt_model.pth\")\n    \n    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, Val F1 Score: {val_f1:.4f}\")\n\n    scheduler.step()\n\nwriter.close()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:15:14.069570Z","iopub.status.idle":"2024-12-16T16:15:14.069988Z","shell.execute_reply.started":"2024-12-16T16:15:14.069772Z","shell.execute_reply":"2024-12-16T16:15:14.069793Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot confusion matrix\ndef plot_confusion_matrix(targets, predictions, class_names):\n    cm = confusion_matrix(targets, predictions)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n\nplot_confusion_matrix(all_targets, all_predictions, train_dataset.dataset.classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:15:14.071303Z","iopub.status.idle":"2024-12-16T16:15:14.071716Z","shell.execute_reply.started":"2024-12-16T16:15:14.071501Z","shell.execute_reply":"2024-12-16T16:15:14.071523Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fungsi untuk menampilkan gambar per kelas dengan prediksi model\ndef show_predictions_per_class(model, dataset, num_classes=20, cols=5):\n    model.eval()\n    rows = (num_classes + cols - 1) // cols\n    fig, axs = plt.subplots(rows, cols, figsize=(15, 3 * rows))\n    axs = axs.flatten()\n\n    class_images = {i: None for i in range(num_classes)}\n\n    for i in range(len(dataset)):\n        image, label = dataset[i]\n        image = image.unsqueeze(0).to(device)\n        with torch.no_grad():\n            output = model(image).logits\n            _, predicted = output.max(1)\n            if class_images[label] is None and predicted.item() == label:\n                class_images[label] = (image.squeeze().cpu(), label, predicted.item())\n                if all(value is not None for value in class_images.values()):\n                    break\n\n    for i in range(num_classes):\n        ax = axs[i]\n        if class_images[i] is not None:\n            img, true_label, pred_label = class_images[i]\n            ax.imshow(img.permute(1, 2, 0).numpy())\n            ax.set_title(f\"True: {train_dataset.dataset.classes[true_label]}, Pred: {train_dataset.dataset.classes[pred_label]}\")\n            ax.axis('off')\n        else:\n            ax.text(0.5, 0.5, 'No Prediction', ha='center', va='center')\n            ax.axis('off')\n\n    for j in range(num_classes, rows * cols):\n        axs[j].axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\nshow_predictions_per_class(model, val_dataset)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:15:14.073132Z","iopub.status.idle":"2024-12-16T16:15:14.073417Z","shell.execute_reply.started":"2024-12-16T16:15:14.073278Z","shell.execute_reply":"2024-12-16T16:15:14.073292Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting Training and Validation Loss and Accuracy\nplt.figure(figsize=(12, 5))\n\n# Loss plot\nplt.subplot(1, 2, 1)\nplt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\nplt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\n# Accuracy plot\nplt.subplot(1, 2, 2)\nplt.plot(range(1, len(train_accs) + 1), train_accs, label='Train Accuracy')\nplt.plot(range(1, len(val_accs) + 1), val_accs, label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:15:14.074360Z","iopub.status.idle":"2024-12-16T16:15:14.074649Z","shell.execute_reply.started":"2024-12-16T16:15:14.074508Z","shell.execute_reply":"2024-12-16T16:15:14.074522Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}