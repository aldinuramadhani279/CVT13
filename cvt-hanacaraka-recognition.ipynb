{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3144322,"sourceType":"datasetVersion","datasetId":1887646},{"sourceId":3799317,"sourceType":"datasetVersion","datasetId":2265176},{"sourceId":7510067,"sourceType":"datasetVersion","datasetId":767979},{"sourceId":9370281,"sourceType":"datasetVersion","datasetId":5682908},{"sourceId":1430623,"sourceType":"datasetVersion","datasetId":609422}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom transformers import AutoImageProcessor, CvtForImageClassification, AutoConfig\nimport numpy as np\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom PIL import Image, UnidentifiedImageError\nimport os\nfrom sklearn.metrics import confusion_matrix, f1_score\nimport matplotlib.pyplot as plt\nfrom torch.utils.tensorboard import SummaryWriter\nimport seaborn as sns\n","metadata":{"id":"iC1-ZNmCw15s","execution":{"iopub.status.busy":"2024-12-16T21:51:26.345958Z","iopub.execute_input":"2024-12-16T21:51:26.346307Z","iopub.status.idle":"2024-12-16T21:51:26.352253Z","shell.execute_reply.started":"2024-12-16T21:51:26.346277Z","shell.execute_reply":"2024-12-16T21:51:26.351298Z"},"trusted":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Tentukan device untuk training (GPU jika tersedia)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T21:51:26.354145Z","iopub.execute_input":"2024-12-16T21:51:26.354735Z","iopub.status.idle":"2024-12-16T21:51:26.371383Z","shell.execute_reply.started":"2024-12-16T21:51:26.354690Z","shell.execute_reply":"2024-12-16T21:51:26.370649Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Hyperparameters dan paths\nBATCH_SIZE = 16\nNUM_CLASSES = 20\nEPOCHS = 100\nLEARNING_RATE = 0.00015836211715780283\nWEIGHT_DECAY = 0.00002683\nIMAGE_SIZE = 224\nDATASET_PATH = '/kaggle/input/d/phiard/aksara-jawa/v3/v3'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T21:51:26.372639Z","iopub.execute_input":"2024-12-16T21:51:26.373465Z","iopub.status.idle":"2024-12-16T21:51:26.385697Z","shell.execute_reply.started":"2024-12-16T21:51:26.373399Z","shell.execute_reply":"2024-12-16T21:51:26.384990Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Load dan konfigurasi model CvT-13\nconfig = AutoConfig.from_pretrained(\"microsoft/cvt-13\")\nconfig.num_labels = NUM_CLASSES\nconfig.hidden_dropout_prob = 0.25416416873049263\nimage_processor = AutoImageProcessor.from_pretrained(\"microsoft/cvt-13\")\nmodel = CvtForImageClassification.from_pretrained(\n    \"microsoft/cvt-13\", config=config, ignore_mismatched_sizes=True\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T21:51:26.387737Z","iopub.execute_input":"2024-12-16T21:51:26.388121Z","iopub.status.idle":"2024-12-16T21:51:26.926622Z","shell.execute_reply.started":"2024-12-16T21:51:26.388079Z","shell.execute_reply":"2024-12-16T21:51:26.925554Z"}},"outputs":[{"name":"stderr","text":"Some weights of CvtForImageClassification were not initialized from the model checkpoint at microsoft/cvt-13 and are newly initialized because the shapes did not match:\n- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([20]) in the model instantiated\n- classifier.weight: found shape torch.Size([1000, 384]) in the checkpoint and torch.Size([20, 384]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"from torchvision import transforms\n\n# Transformasi untuk data training\ntrain_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),            # Flipping horizontal acak\n    transforms.RandomRotation(20),                # Rotasi acak antara -20 hingga 20 derajat\n    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.8, 1.0)),  # Crop acak dengan ukuran tertentu\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Variasi warna\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalisasi\n])\n\n# Transformasi untuk data validasi (tanpa augmentasi)\nval_transform = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),               # Resize gambar untuk validasi\n    transforms.CenterCrop(IMAGE_SIZE),           # Crop di tengah\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalisasi\n])\n\n# CustomImageFolder dengan transformasi yang telah diubah\nclass CustomImageFolder(Dataset):\n    def __init__(self, root, transform=None):\n        self.samples = []\n        self.targets = []\n        self.transform = transform\n        classes, class_to_idx = self._find_classes(root)\n        self.class_to_idx = class_to_idx\n        self.classes = classes\n\n        for target_class in sorted(class_to_idx.keys()):\n            class_index = class_to_idx[target_class]\n            target_dir = os.path.join(root, target_class)\n            if not os.path.isdir(target_dir):\n                continue\n            for root_, _, fnames in sorted(os.walk(target_dir, followlinks=True)):\n                for fname in sorted(fnames):\n                    path = os.path.join(root_, fname)\n                    try:\n                        with Image.open(path) as img:\n                            img.verify()\n                        self.samples.append((path, class_index))\n                        self.targets.append(class_index)\n                    except (UnidentifiedImageError, OSError):\n                        print(f\"Gambar korup dilewati: {path}\")\n                        continue\n\n    def __getitem__(self, index):\n        path, target = self.samples[index]\n        with Image.open(path) as sample:\n            sample = sample.convert('RGB')\n        \n        # Apply transformation\n        if self.transform:\n            sample = self.transform(sample)\n        \n        return sample, target\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, index):\n        path, target = self.samples[index]\n        with Image.open(path) as sample:\n            sample = sample.convert('RGB')\n        inputs = image_processor(images=sample, return_tensors=\"pt\")\n        return inputs[\"pixel_values\"].squeeze(0), target\n\n    def _find_classes(self, dir):\n        classes = [d.name for d in os.scandir(dir) if d.is_dir()]\n        classes.sort()\n        class_to_idx = {classes[i]: i for i in range(len(classes))}\n        return classes, class_to_idx\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T21:51:26.928197Z","iopub.execute_input":"2024-12-16T21:51:26.928559Z","iopub.status.idle":"2024-12-16T21:51:26.942078Z","shell.execute_reply.started":"2024-12-16T21:51:26.928528Z","shell.execute_reply":"2024-12-16T21:51:26.940942Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Load dataset dan lakukan pembagian 80/20\ntrain_dataset = CustomImageFolder(os.path.join(DATASET_PATH, 'train'))\nval_dataset = CustomImageFolder(os.path.join(DATASET_PATH, 'val'))\n\n# Pembagian test dataset ke training dan validation 80/20\ntrain_size = int(0.8 * len(train_dataset))\ntest_size = len(train_dataset) - train_size\ntrain_dataset, test_dataset = random_split(train_dataset, [train_size, test_size])\n\n# Membuat DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T21:51:26.943043Z","iopub.execute_input":"2024-12-16T21:51:26.943366Z","iopub.status.idle":"2024-12-16T21:51:32.940195Z","shell.execute_reply.started":"2024-12-16T21:51:26.943333Z","shell.execute_reply":"2024-12-16T21:51:32.939470Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Hitung class weights untuk ketidakseimbangan kelas\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(train_dataset.dataset.targets),\n    y=train_dataset.dataset.targets\n)\nclass_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T21:51:32.941233Z","iopub.execute_input":"2024-12-16T21:51:32.941565Z","iopub.status.idle":"2024-12-16T21:51:32.948484Z","shell.execute_reply.started":"2024-12-16T21:51:32.941536Z","shell.execute_reply":"2024-12-16T21:51:32.947639Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# Loss function\ncriterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)\n\n# Optimizer\noptimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n\n# Scheduler\nscheduler = CosineAnnealingLR(optimizer, T_max=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T21:51:32.950704Z","iopub.execute_input":"2024-12-16T21:51:32.951103Z","iopub.status.idle":"2024-12-16T21:51:32.963400Z","shell.execute_reply.started":"2024-12-16T21:51:32.951073Z","shell.execute_reply":"2024-12-16T21:51:32.962463Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Fungsi train\ndef train(model, loader, optimizer, criterion):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n    for data, target in loader:\n        data, target = data.to(device), target.to(device)\n        output = model(data).logits\n        loss = criterion(output, target)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        _, predicted = output.max(1)\n        correct += predicted.eq(target).sum().item()\n        total += target.size(0)\n    return total_loss / len(loader), 100. * correct / total\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T21:51:32.964754Z","iopub.execute_input":"2024-12-16T21:51:32.965126Z","iopub.status.idle":"2024-12-16T21:51:32.981266Z","shell.execute_reply.started":"2024-12-16T21:51:32.965085Z","shell.execute_reply":"2024-12-16T21:51:32.980652Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# Fungsi validasi\ndef validate(model, loader, criterion):\n    model.eval()\n    total_loss = 0\n    correct = 0\n    total = 0\n    all_targets = []\n    all_predictions = []\n    with torch.no_grad():\n        for data, target in loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data).logits\n            loss = criterion(output, target)\n            total_loss += loss.item()\n            _, predicted = output.max(1)\n            correct += predicted.eq(target).sum().item()\n            total += target.size(0)\n            all_targets.extend(target.cpu().numpy())\n            all_predictions.extend(predicted.cpu().numpy())\n    f1 = f1_score(all_targets, all_predictions, average='weighted')\n    return total_loss / len(loader), 100. * correct / total, f1, all_targets, all_predictions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T21:51:32.982292Z","iopub.execute_input":"2024-12-16T21:51:32.982573Z","iopub.status.idle":"2024-12-16T21:51:32.998074Z","shell.execute_reply.started":"2024-12-16T21:51:32.982548Z","shell.execute_reply":"2024-12-16T21:51:32.997357Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"writer = SummaryWriter()\ntrain_losses = []\ntrain_accs = []\nval_losses = []\nval_accs = []\nval_f1_scores=[]\n# Initialize early stopping parameters\npatience = 10  # Number of epochs to wait for improvement\ncounter = 0  # Counter to track epochs without improvement\nbest_val_acc = 0\nfor epoch in range(EPOCHS):\n    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n    val_loss, val_acc, val_f1, all_targets, all_predictions = validate(model, val_loader, criterion)\n    train_losses.append(train_loss)\n    train_accs.append(train_acc)\n    val_losses.append(val_loss)\n    val_accs.append(val_acc)\n    val_f1_scores.append(val_f1)\n\n    writer.add_scalars('Loss', {'Train': train_loss, 'Val': val_loss}, epoch)\n    writer.add_scalars('Accuracy', {'Train': train_acc, 'Val': val_acc}, epoch)\n    writer.add_scalar('F1_Score/Val', val_f1, epoch)\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), \"best_cvt_model.pth\")\n        counter = 0  # Reset counter if validation accuracy improves\n    else:\n        counter += 1\n\n    # Early stopping condition\n    if counter >= patience:\n        print(f\"Early stopping after epoch {epoch+1} due to no improvement in validation accuracy.\")\n        break\n\n    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, Val F1 Score: {val_f1:.4f}\")\n\n    scheduler.step()\n\nwriter.close()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T21:51:32.999204Z","iopub.execute_input":"2024-12-16T21:51:32.999522Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\nTrain Loss: 2.6598, Train Acc: 18.57%\nVal Loss: 2.4329, Val Acc: 17.50%, Val F1 Score: 0.1412\nEpoch 2/100\nTrain Loss: 1.6573, Train Acc: 58.21%\nVal Loss: 1.0003, Val Acc: 78.12%, Val F1 Score: 0.7680\nEpoch 3/100\nTrain Loss: 1.1264, Train Acc: 74.87%\nVal Loss: 0.9204, Val Acc: 78.54%, Val F1 Score: 0.7890\nEpoch 4/100\nTrain Loss: 0.9890, Train Acc: 77.54%\nVal Loss: 0.7275, Val Acc: 85.62%, Val F1 Score: 0.8531\nEpoch 5/100\nTrain Loss: 0.9219, Train Acc: 79.22%\nVal Loss: 0.7400, Val Acc: 85.21%, Val F1 Score: 0.8452\nEpoch 6/100\nTrain Loss: 0.9247, Train Acc: 78.70%\nVal Loss: 0.7382, Val Acc: 85.62%, Val F1 Score: 0.8563\nEpoch 7/100\nTrain Loss: 0.9058, Train Acc: 79.74%\nVal Loss: 0.7034, Val Acc: 87.71%, Val F1 Score: 0.8766\nEpoch 8/100\nTrain Loss: 0.8828, Train Acc: 80.38%\nVal Loss: 0.7090, Val Acc: 87.92%, Val F1 Score: 0.8758\nEpoch 9/100\nTrain Loss: 0.9085, Train Acc: 79.40%\nVal Loss: 0.6998, Val Acc: 87.71%, Val F1 Score: 0.8763\nEpoch 10/100\nTrain Loss: 0.8873, Train Acc: 79.98%\nVal Loss: 0.6901, Val Acc: 87.71%, Val F1 Score: 0.8762\nEpoch 11/100\nTrain Loss: 0.8485, Train Acc: 81.54%\nVal Loss: 0.6921, Val Acc: 88.12%, Val F1 Score: 0.8816\nEpoch 12/100\nTrain Loss: 0.8731, Train Acc: 81.08%\nVal Loss: 0.6879, Val Acc: 88.33%, Val F1 Score: 0.8821\nEpoch 13/100\nTrain Loss: 0.8423, Train Acc: 82.18%\nVal Loss: 0.6973, Val Acc: 88.33%, Val F1 Score: 0.8831\nEpoch 14/100\nTrain Loss: 0.8923, Train Acc: 79.86%\nVal Loss: 0.7212, Val Acc: 87.92%, Val F1 Score: 0.8788\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Plot confusion matrix\ndef plot_confusion_matrix(targets, predictions, class_names):\n    cm = confusion_matrix(targets, predictions)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n\nplot_confusion_matrix(all_targets, all_predictions, train_dataset.dataset.classes)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fungsi untuk menampilkan gambar per kelas dengan prediksi model\ndef show_predictions_per_class(model, dataset, num_classes=20, cols=5):\n    model.eval()\n    rows = (num_classes + cols - 1) // cols\n    fig, axs = plt.subplots(rows, cols, figsize=(15, 3 * rows))\n    axs = axs.flatten()\n\n    class_images = {i: None for i in range(num_classes)}\n\n    for i in range(len(dataset)):\n        image, label = dataset[i]\n        image = image.unsqueeze(0).to(device)\n        with torch.no_grad():\n            output = model(image).logits\n            _, predicted = output.max(1)\n            if class_images[label] is None and predicted.item() == label:\n                class_images[label] = (image.squeeze().cpu(), label, predicted.item())\n                if all(value is not None for value in class_images.values()):\n                    break\n\n    for i in range(num_classes):\n        ax = axs[i]\n        if class_images[i] is not None:\n            img, true_label, pred_label = class_images[i]\n            ax.imshow(img.permute(1, 2, 0).numpy())\n            ax.set_title(f\"True: {train_dataset.dataset.classes[true_label]}, Pred: {train_dataset.dataset.classes[pred_label]}\")\n            ax.axis('off')\n        else:\n            ax.text(0.5, 0.5, 'No Prediction', ha='center', va='center')\n            ax.axis('off')\n\n    for j in range(num_classes, rows * cols):\n        axs[j].axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\nshow_predictions_per_class(model, val_dataset)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting Training and Validation Loss and Accuracy\nplt.figure(figsize=(12, 5))\n\n# Loss plot\nplt.subplot(1, 2, 1)\nplt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\nplt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\n# Accuracy plot\nplt.subplot(1, 2, 2)\nplt.plot(range(1, len(train_accs) + 1), train_accs, label='Train Accuracy')\nplt.plot(range(1, len(val_accs) + 1), val_accs, label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}